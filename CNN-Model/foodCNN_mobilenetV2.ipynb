{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#running on tensorflow backend\n",
    "#tensorflow version: tensorflow-gpu 1.13.1\n",
    "#keras version: 2.2.4\n",
    "#numpy version: 1.16.3\n",
    "#used pretrained model: MobileNetV2\n",
    "'''Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., & Chen, L. (2018). \n",
    "    MobileNetV2: Inverted Residuals and Linear Bottlenecks. \n",
    "    Arxiv E-Prints, arXiv:1801.04381.'''\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.applications import imagenet_utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "train_path = 'vegetables'\n",
    "valid_path = 'vegetables_val'\n",
    "test_path = 'vegetables_test'\n",
    "\n",
    "\n",
    "IMAGE_SIZE = 224      # Image height and width\n",
    "BATCH_SIZE = 64       # How many images will be processed each time\n",
    "\n",
    "# Generate training set, validation set and test set\n",
    "train_generator = ImageDataGenerator(\n",
    "    #horizontal_flip=True,\n",
    "    #rotation_range=30,\n",
    "    preprocessing_function=keras.applications.mobilenet_v2.preprocess_input).flow_from_directory(\n",
    "    train_path, target_size=(IMAGE_SIZE,IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "val_generator = ImageDataGenerator(preprocessing_function=keras.applications.mobilenet_v2.preprocess_input).flow_from_directory(\n",
    "    valid_path, target_size=(IMAGE_SIZE,IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=keras.applications.mobilenet_v2.preprocess_input).flow_from_directory(\n",
    "    valid_path, target_size=(IMAGE_SIZE,IMAGE_SIZE), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "for image_batch, label_batch in train_generator:\n",
    "  break\n",
    "image_batch.shape, label_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the label file\n",
    "print (train_generator.class_indices)\n",
    "\n",
    "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
    "\n",
    "with open('labels.txt', 'w') as f:\n",
    "  f.write(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                              include_top=False, \n",
    "                                              weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transfer learning step, freeze layers in base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "# Total class numbers\n",
    "CLASS_NUM = 84\n",
    "# Create the squential model\n",
    "model = models.Sequential()\n",
    " \n",
    "# Add the MobileNetV2 convolutional base model\n",
    "model.add(base_model)\n",
    " \n",
    "# Add new layers\n",
    "model.add(layers.AveragePooling2D())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(CLASS_NUM, activation='softmax'))\n",
    " \n",
    "# Show a summary of the model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model using Adam optimizer\n",
    "model.compile(optimizer=optimizers.Adam(0.0001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "print('Number of trainable variables = {}'.format(len(model.trainable_variables)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "epochs = 5\n",
    "\n",
    "history = model.fit(train_generator, epochs=epochs, validation_data=val_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw a graph for accuracy and loss\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,3.5])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuning step 1: unfreeze layers in base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Fine tuning top 55 layers\n",
    "fine_tuning = 100\n",
    "\n",
    "# Fine tuning Step 2: Freeze the bottom 100 layers\n",
    "for layer in base_model.layers[:fine_tuning]:\n",
    "  layer.trainable =  False\n",
    "\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = optimizers.Adam(0.0001),\n",
    "              metrics=['accuracy'])\n",
    "filepath=\"mobilenetV2_model_best.h5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "# print the number of trainable variables\n",
    "print('Number of trainable variables = {}'.format(len(model.trainable_variables)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "history_fine = model.fit(train_generator, \n",
    "                         epochs=20,\n",
    "                         validation_data=val_generator,\n",
    "                         callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a graph for accuracy and loss\n",
    "acc = history_fine.history['acc']\n",
    "val_acc = history_fine.history['val_acc']\n",
    "\n",
    "loss = history_fine.history['loss']\n",
    "val_loss = history_fine.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0, 1.5])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "keras_file = \"food_mobilenetV2_model.h5\"\n",
    "tf.keras.models.save_model(model, keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a single prediction\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "img = load_img('vegetables_test/carrot_cake/1381243.jpg',target_size=(224, 224))  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 224, 224)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 224, 224)\n",
    "x = keras.applications.mobilenet.preprocess_input(x)\n",
    "prediction = model.predict(x)\n",
    "maximum = max(prediction[0])\n",
    "[i for i, j in enumerate(prediction[0]) if j == maximum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the fuction to draw a confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make prediction on test images\n",
    "test_labels = test_batches.classes\n",
    "predictions = model.predict_generator(test_batches, steps = 100,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the labels\n",
    "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))\n",
    "test_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot the confusion matrix\n",
    "cm_plot_labels = [i for i in range(84)]\n",
    "plt.figure()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(28, 28)\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
